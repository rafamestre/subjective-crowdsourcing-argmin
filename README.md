# Benchmark Evaluation for Tasks with Highly Subjective Crowdsourced Annotations: Case study in Argument Mining of Political Debates

This is the accompanying dataset, codes and supplementary information of the paper "Benchmark Evaluation for Tasks with Highly Subjective Crowdsourced Annotations: Case study in Argument Mining of Political Debates", published at the 2nd NEATCLasS workshop 2023 at the 17th International AAAI Conference on Web and Social Media (ICWSM).


